
;; update the corner model after loading corner.ind, using 10 iterations over 
;;    the training set with learning parameters 1.0 each. 
;; time(f) shows the timing of execution
;; The beam search is turned off before training.
;; You can see the active rule set after the second line of '='s

> (beam-off) 
> (time (update-model "corner" 10 1.0 1.0 :load t))
*Beamp* = NIL  *Beam-exp* = 0.9

======================= l o a d i n g =======================================
; loading #P"/Users/bozsahin/mysrc/myrepos/ccglab-grammars/corner/corner.ind"

Project [corner] is assumed to consist of
-----------------------------------------------------------------------------
  CCG grammar source : corner.ccg $
    Its token form   : corner.lisptokens $
  Deduction grammar  : corner.ded $ (derived from corner.lisptokens)
  Induction grammar  : corner.ind #
  Supervision source : corner.sup ^
  Model-specific code: corner.lisp ^
   and other model-specific files you may create.
       *CCG-GRAMMAR* : set from corner.ind
  *LEX-RULES-TABLE*  : set from corner.ind
Expected files       : $ for deduction, # for induction, ^ for model development
=============================================================================

Supervision file loaded: corner.sup
Done. use (show-training/save-training) to see/save the resultsT
> (show-training)
The rule set used in the experiment:
To change a switch, use (setf <switchname> <value>)
	      where <value> is T (on) or NIL (off)
	  *f-apply*     T
	  *b-apply*     T
	  *f-comp*      T
	  *b-comp*      T
	  *fx-comp*     T
	  *bx-comp*     T
	  *f-sub*       T
	  *b-sub*       T
	  *fx-sub*      T
	  *bx-sub*      T
          *f-subbar*    NIL
	  *b-subbar*    NIL
	  *fx-subbar*   NIL
	  *bx-subbar*   NIL
	  *f-subcomp*   T
	  *b-subcomp*   T
	  *fx-subcomp*  T
	  *bx-subcomp*  T
          *f2-comp*     T
	  *b2-comp*     T
	  *fx2-comp*    T
	  *bx2-comp*    T
	  *f2-sub*      T
	  *b2-sub*      T
	  *fx2-sub*     T
	  *bx2-sub*     T
	  *f3-comp*     T
	  *b3-comp*     T
	  *fx3-comp*    T
	  *bx3-comp*    T

;; these are the training parameters

Training parameters: N = 10 alpha0 = 1.0 c = 1.0 n = 3  *Beamp* = NIL  *Beam-exp* = 0.9

;; here is the grammar, one line per each entry, before and after training
;; Note that forward subject type-raising (str) outranks bakcward subject type-raising after
;; training, although they were assumed to be equally useful before training.

;; Similarly, forward object type raising is less favoured afterwards.

Model parameters before and after training
================================================
key   lex             initial  final    diff 
------------------------------------------------
1     THE               0.1 .1590357  (.0590357)
2     MAN               0.1 0.039547  (-.060453)
3     IN                0.1 .1713326  (.0713326)
4     CORNER            0.1 .2976355  (.1976355)
5     STR               0.1 .3476489  (.2476489)
6     BSTR              0.1 0.223723  (0.123723)
7     OTR               0.1 .0050866  (-.094913)
8     FOTR              0.1 -.103643  (-.203643)
9     HITS              0.1 0.100001  (0.000001)
================================================
NIL
> (dribble)
